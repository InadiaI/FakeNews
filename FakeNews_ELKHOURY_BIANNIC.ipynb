{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FakeNews-ELKHOURY-BIANNIC.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPVGWdGVC+69HbO0Nr1tPPk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InadiaI/FakeNews/blob/main/FakeNews_ELKHOURY_BIANNIC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG6guxem5-8C"
      },
      "source": [
        "**Subject :** Create an algorithm for classifying news are \"fake\" or \"real\".\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "_______________________________________________________\n",
        "\n",
        "[1] Datasets from kaggle.com\n",
        "\n",
        "https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset\n",
        "\n",
        "https://www.kaggle.com/c/fake-news/data \n",
        "\n",
        "https://www.kaggle.com/hassanamin/textdb3\n",
        "\n",
        "https://www.kaggle.com/snapcrack/all-the-news (only \"real\")\n",
        "\n",
        "https://www.kaggle.com/mrisdal/fake-news (only fake)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87t38f2k61Nd"
      },
      "source": [
        "1- You need datasets containing news with a label \"fake\" or \"real\". You can use datasets from kaggle.com [1] or any other dataset you can find (github, google colab, ...).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZAuIa487TId",
        "outputId": "d9b64d72-0265-437e-a77b-dc94a2b4eea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#We start by importing keras\n",
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqGDiTvrCWZT",
        "outputId": "34b044e8-20cf-4374-8445-f27ab1d5ba26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# https://www.kaggle.com/c/fake-news/data this link has the data already classified in train test and submit\n",
        "# https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset this link has  real and fake datasets\n",
        "!pip install kaggle\n",
        "api_token = {\"username\":\"nadiaelkhoury\",\"key\":\"0dda7b45f140e015af3441566c4be78d\"}\n",
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"nadiaelkhoury\"\n",
        "os.environ['KAGGLE_KEY'] = \"0dda7b45f140e015af3441566c4be78d\"\n",
        "!kaggle datasets download -d iarunava/happy-house-dataset\n",
        "if not os.path.exists(\"/content/competitions/happy-house-dataset\"):\n",
        "    os.makedirs(\"/content/competitions/happy-house-dataset\")\n",
        "os.chdir('/content/competitions/happy-house-dataset')\n",
        "for file in os.listdir():\n",
        "    zip_ref = zipfile.ZipFile(file, 'r')\n",
        "    zip_ref.extractall()\n",
        "    zip_ref.close()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (0.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Downloading happy-house-dataset.zip to /content\n",
            " 67% 5.00M/7.49M [00:00<00:00, 25.3MB/s]\n",
            "100% 7.49M/7.49M [00:00<00:00, 29.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyTLbmjF7M12"
      },
      "source": [
        "Analysis of the dataset. What kind of data is in your dataset ?\n",
        "Then you will process the data. Try to represent the data with Bag of Word\n",
        "Apply a standard (not deep learning) machine learning algorithm.\n",
        "Compute and analyze the performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vi4r5ir7UH-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPpIeQT17Yr2"
      },
      "source": [
        "try to apply the same algorithm to a different dataset,\n",
        "use more complex representation of the data (Word2Vect, or anything else),\n",
        "try to improve or change the ML algorithm (for exemple try to use deepLearning),\n",
        "In each case, compare the performances obtained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpJPOzNZ7g8u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7Z-L9ev7iNu"
      },
      "source": [
        "\n",
        "It is not expected that you try all of this, you are free to chose the representation of data that you want and the ML that you want. But be sure to understand what you are doing as you will need to present it.\n"
      ]
    }
  ]
}